# üê±üê∞ Cats VS Rabbits Classification

## Descripci√≥n del proyecto 

Este proyecto tiene como objetivo desarrollar un modelo de aprendizaje autom√°tico  (Machine Learning) capaz de clasificar im√°genes de forma binaria, identificando si pertenecen a un **gato** o un **conejo**. A trav√©s del entrenamiento con un conjunto de im√°genes variadas, el modelo busca aprender a reconocer patrones visuales distintivos entre ambas especies, incluso en presencia de diferentes posturas, razas y fondos.

## Descripci√≥n del Dataset

El conjunto de datos utilizado fue obtenido de la plataforma Kaggle. Contiene im√°genes de **gatos y conejos** en diversas condiciones: m√∫ltiples razas, posturas y escenarios visuales, lo que permite entrenar un modelo m√°s robusto y generalizable.

### Caracter√≠sticas del dataset:

- Contiene **2,000 im√°genes** distribuidas en las capetas test, train y validation:
    - `Cat`: 1,000 im√°genes de gatos
        - Train: 800 im√°genes
        - Test: 10 im√°genes
        - Validation: 207 im√°genes
    - `Rabbit`: 1,000 im√°genes
        - Train: 800 im√°genes
        - Test: 5 im√°genes
        - Validation: 207 im√°genes
- Formato de imagen: `.jpg`
- No contiene etiquetas adicionales como raza, edad o ubicaci√≥n.
- Todas las im√°genes ya han sido redimensionadas a (300, 300).

### Obtener, generar o aumentar un set de datos.
El dataset utilizado fue descargado desde la plataforma Kaggle [(Munir Yadi, ‚ÄúCat vs Rabbit‚Äù)](https://www.kaggle.com/datasets/muniryadi/cat-vs-rabbit) 

Se redistribuy√≥ de forma manual la informaci√≥n contenida en el dataset y realiz√≥ una limpieza en los datos que presentaban elementos no relacionados (im√°genes con demasiado zoom unicamente de pelaje, im√°genes de pasto) para tener un mejor equilibro en los datos para entrenar, validar y probar el modelo de ML

- Entrenamiento: 70%
    - `Cat:` 700 im√°genes
    - `Rabbit`: 700 im√°genes
- Validaci√≥n: 15%
    - `Cat:` 150 im√°genes
    - `Rabbit`: 150 im√°genes
- Prueba: 15%
    - `Cat:` 150 im√°genes
    - `Rabbit`: 150 im√°genes
    

### Escalamiento y Preprocesado de Datos
Para mejorar el rendimiento y la capacidad de generalizaci√≥n del modelo, se implementaron t√©cnicas de preprocesado utilizando TensorFlow y Keras. 

Las im√°genes originales ten√≠an un tama√±o de 300x300 p√≠xeles, pero se redimensionaron a 150x150 para poder acelerar el entrenamiento y reducir el uso de memoria (RAM o GPU) adem√°s, simplica los c√°lculos al disminuir la cantidad de p√≠xeles por imagen.

Igualmente preserva suficiente informaci√≥n visual para tareas de clasificaci√≥n binaria como en este caso es la distinci√≥n entre gatos y conejos, ya que estas clases tienen caracter√≠sticas f√°cilmente detectables incluso a menor resoluci√≥n no hace falta tener una alta resoluci√≥n para poder distinguir entre ambas especies.

- `rescale = 1./255,` : Convierte los valores de p√≠xeles de [0, 255] a [0, 1]
- `rotation_range=20`:  Gira aleatoriamente la imagen en un rango de ¬±20 grados
- `width_shift_range=0.1`:  Desplaza la imagen horizontalmente hasta un 10%
- `height_shift_range=0.2`: Desplaza la imagen verticalmente hasta un 10%
- `zoom_range=0.15`: Aplica un zoom aleatorio de hasta un 15%
- `horizontal_flip = True:` Invierte horizontalmente la imagen de forma aleatoria
- `brightness_range=[0.5, 1.2]:` Ajusta aleatoriamente el brillo entre 50% y 120%

## Implementaci√≥n del modelo
### Algoritmo 

La tarea de clasificar im√°genes de gatos y conejos implica afrontar variaciones de iluminaci√≥n, fondo, pelajes y poses. Para abordar estos desaf√≠os se evaluaron distintos enfoques (SVM, HOG¬†+¬†SVM, Random Forest), pero finalmente se opt√≥ por una Convolutional Neural Network (CNN) debido a los siguientes factores clave:

- **Aprendizaje autom√°tico de caracter√≠sticas:** 
    A diferencia de HOG o SIFT, la CNN aprende jerarqu√≠as de bordes, texturas y formas directamente de los p√≠xeles sin ingenier√≠a manual.

- **Buen desempe√±o con conjuntos de datos moderados:**  
   Con solo 2 000 im√°genes, t√©cnicas de *data augmentation* (rotaciones, flips, cambios de brillo) permiten a la CNN generalizar mejor que modelos tradicionales con caracter√≠sticas fijas.

- **Flexibilidad para adaptarse a diferentes tama√±os de im√°genes:** 
    Las convoluciones y el pooling permiten entrenar la red con resoluciones variables sin perder detalles importantes. Esto facilita integrar fotos obtenidas con c√°maras distintas (smartphone, DSLR, webcam) sin reescalar todo a un tama√±o fijo, manteniendo la nitidez cuando est√° disponible. (Sin embargo esta se modific√≥ por temas de rendimiento)

La elecci√≥n de una Convolutional Neural Network (CNN) para la clasificaci√≥n binaria de gatos y conejos se fundamenta en que, aunque ambas especies comparten rasgos generales (pelaje y siluetas similares), existen detalles visuales finos como longitud y posici√≥n de las orejas, forma del hocico, proporciones de la cabeza; que la arquitectura convolucional aprende de forma jer√°rquica y autom√°tica. 

El conjunto de ‚âà 2 000 im√°genes disponible, reforzado con t√©cnicas de data augmentation (volteos, rotaciones leves, ajustes de brillo), proporciona la diversidad necesaria para entrenar la red reduciendo las posibilidades de tener un overtfitting.

Adem√°s, muchos de los conceptos y herramientas empleados (capas convolucionales, pooling, data augmentation, capas flatten y densas) ya se trabajaron en clase, lo que facilita la implementaci√≥n pr√°ctica. As√≠, la CNN ofrece la combinaci√≥n √≥ptima de precisi√≥n, robustez ante variaciones de fondo e iluminaci√≥n y escalabilidad para incorporar nuevas clases en el futuro con un ajuste m√≠nimo.


### Para la implementaci√≥n del modelo se utilizaron los siguientes papers:

- [Custom CNN architectures for skin disease classification: binary and multi-class performance](https://www.semanticscholar.org/paper/Custom-CNN-architectures-for-skin-disease-binary-Gupta-Nirmal/26208d4b3255702dfe9ec6b257c7a6d6d8c2dd95?)

- [Binary Image Classification Through an Optimal Topology for Convolutional Neural Networks](https://asrjetsjournal.org/index.php/American_Scientific_Journal/article/view/5938)

- [Multi-CNN models with Pretraining for Binary Classification in Skin Cancer](https://ieeexplore.ieee.org/document/9750709)


## Arquitectura de una CNN y Model
### **¬øQu√© es una CNN?**
Una red neuronal convolucional (CNN) es un tipo de red neuronal artificial, especialmente efectiva para el procesamiento y an√°lisis de datos visuales como im√°genes y videos. Se basa en el principio de las convoluciones para extraer caracter√≠sticas de la entrada y luego las usa para realizar tareas como clasificaci√≥n, detecci√≥n de objetos, segmentaci√≥n, entre otras. 

Las CNN est√°n compuestas por tres tipos de capas: 

- Capa de convoluci√≥n.
- Capa de agrupaci√≥n.
- Capa completamente conectada (relu y salida). 

<img src="assets/Arquitectura_CNN.png" width="600">

Se elegi√≥ la arquitectura simple de los papers con el accuracy m√°s alto para los modelos binarios, la cual consta de las siguientes capas:

- `Capa convolucional (Conv2D)` :
    - Se define una capa convolucional con 32 filtros de tama√±o 3 √ó 3 y funci√≥n de activaci√≥n ReLU.
    - La capa espera entradas de im√°genes con tama√±o 150 √ó 150 p√≠xeles y 3 canales de color (RGB).
    - Al aplicar cada filtro, se produce un mapa de activaci√≥n que resalta bordes y texturas b√°sicas presentes en las fotos de gatos y conejos.
    - ReLU deja pasar valores positivos y pone en cero los negativos para que la red aprenda mejor.

- `Capa de agrupaci√≥n (MaxPooling2D)` :
    -  Se aplica un MaxPooling con ventana 2 √ó 2 para reducir la salida de la capa convolucional anterior.
    -  La capa de pooling reduce la dimensionalidad de la imagen al agrupar regiones adyacentes de p√≠xeles y tomar el valor m√°ximo de cada regi√≥n
    -  Esto ayuda a reducir la cantidad de par√°metros y se mantiene la informaci√≥n m√°s relevante para la clasificaci√≥n.

- `Segunda capa convolucional (Conv2D)` :
    - Contiene 64 filtros de tama√±o 3 √ó 3 y activaci√≥n ReLU.
    - Detecta patrones m√°s complejos.
    - ReLU vuelve a filtrar los valores negativos, acelerando el aprendizaje.

- `Segunda capa de agrupaci√≥n (MaxPooling2D)` :
    - MaxPooling 2 √ó 2 reduce nuevamente las dimensiones espaciales.
    - Se mantiene la informaci√≥n m√°s relevante para la clasificaci√≥n.


- `Tercera capa convolucional (Conv2D)` :
    - Contiene 128 filtros de tama√±o 3 √ó 3 y activaci√≥n ReLU.
    - Identifica patrones a√∫n m√°s complejos.

- `Tercera capa de agrupaci√≥n (MaxPooling2D)` :
    - MaxPooling 2 √ó 2 reduce nuevamente las dimensiones espaciales.
    - Se mantiene la informaci√≥n m√°s relevante para la clasificaci√≥n.

- `Aplanar salida (Flatten)` :
    - Convierte la salida de las capas convolucionales y de pooling en un vector unidimensional.
    - Prepara los datos para conectarse con las neuronas densas.

- `Capa densa (Dense)` :
    - Se define primero una capa densa con 128 neuronas y funci√≥n de activaci√≥n ReLU.

- `Capa de salida (Dense)` :
    - Tiene 1 neurona con activaci√≥n sigmoide.
    - Devuelve un valor entre 0 y 1 que indica la probabilidad de que la imagen sea de una clase (configuraci√≥n t√≠pica para problemas de clasificaci√≥n binaria).

- `Dropout (Dropout)` :
    - Se a√±ade una capa Dropout con tasa 0.3 (30%), que desactiva aleatoriamente el 30% de las neuronas durante el entrenamiento.

Ayuda a prevenir el sobreajuste mejorando la capacidad de generalizaci√≥n del modelo.

## Resultados y Evaluaci√≥n del Modelo
### Selecci√≥n de m√©tricas
La selecci√≥n de m√©tricas tienen como referencia los papers, ya que, son las m√°s adecuadas y comunes para evaluar modelos de clasificaci√≥n binaria. 

- `Accuracy` : Una m√©trica para observar cuantas de las predicciones positivas son correctas. Se centra en la calidad de las predicciones positivas del modelo.

- `Precisi√≥n` : Indica cu√°ntas de las predicciones positivas fueron realmente correctas.

    _TP / (TP / FP)_

- `Recall` : Mide cu√°ntos de los casos positivos reales fueron correctamente detectados

    _TP / (TP / NP)_
    _
- `F1-Score` : Promedio arm√≥nico entre precisi√≥n y recall; eval√∫a la eficiencia general del modelo combinando la precision y el recall. 

    _(Precisi√≥n * Recall)/(Precisi√≥n + Recall)_

- `Support` : N√∫mero de muestras reales en cada clase.

    _No es una f√≥rmula, es un conteo simple de instancias por clase_

Finalmente de forma visual se usa una matriz de confusi√≥n ya que muestra como se distribuyen las predicci√≥nes correctas e incorrectas en cada clase 

<img src="assets/matriz_confusi√≥n.png" width="400">

### Primeros resultados

El modelo fue entrenado durante 15 epocas obteniendo los siguientes resultados: 

**test accuracy: 0.8413**

Posterior a eso se realiz√≥ la evaluaci√≥n del modelo con las m√©tricas mencionadas anteriormente:
| Clase   | Precisi√≥n | Recall | F1-Score | Soporte |
|---------|-----------|--------|----------|---------|
| Gato    | 0.78      | 0.78   | 0.78     | 160     |
| Conejo  | 0.80      | 0.91   | 0.85     | 155     |
| **Macro avg** | **0.80** | **0.84** | **0.84** | 315     |
| **Weighted avg** | **0.80** | **0.84** | **0.84** | 315     |

Las metricas indican que el modelo funciona mejor detectando conejos que gatos, ya que tiene mayor recall y F1-score para esa clase. Esto significa que acierta m√°s cuando se trata de reconocer conejos, mientras que comete m√°s errores al clasificar gatos. Las m√©tricas promedio indican que el rendimiento es equilibrado entre ambas clases, y no hay un sesgo fuerte hacia una sola sin embargo puede mejorar en la identificaci√≥n de gatos que es donde m√°s problemas est√° teniendo.

#### Matriz de Confusi√≥n

Dichas m√©tricas tambien se ven reflejadas en la matriz de confusi√≥n

- 124 (Verdaderos Positivos de Gato): El modelo clasific√≥ correctamente 124 im√°genes que realmente eran de gato.

- 141 (Verdaderos Positivos de Conejo): Clasific√≥ correctamente 141 im√°genes de conejo.

- 36 (Falsos Negativos de Gato): 36 gatos fueron mal clasificados como conejos.

- 14 (Falsos Positivos de Gato): 14 conejos fueron mal clasificados como gatos.


<img src="assets/matriz_modelo.png" width="400">

#### Gr√°ficas de test y val

**Accuracy**
<img src="assets/acc_train_val.png" width="400">

**Loss**
<img src="assets/loss_train_val.png" width="400">

Las gr√°ficas de entrenamiento muestran un comportamiento adecuado del modelo. 
La precisi√≥n tanto en entrenamiento como en validaci√≥n mejora con el paso de las √©pocas, lo que indica que el modelo est√° aprendiendo progresivamente a clasificar correctamente las im√°genes. Por otro lado, la gr√°fica de p√©rdida muestra una disminuci√≥n constante en el conjunto de entrenamiento, mientras que la p√©rdida en validaci√≥n tambi√©n tiende a disminuir. Sin embargo, en ambas gr√°ficas se observan fluctuaciones en las m√©tricas de validaci√≥n que podr√≠an ser se√±ales de overfitting ya que podr√≠a estar empezando a ajustarse demasiado a patrones espec√≠ficos del conjunto de entrenamiento. 

