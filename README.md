# üê±üê∞ Cats VS Rabbits Classification

## Descripci√≥n del proyecto 

Este proyecto tiene como objetivo desarrollar un modelo de aprendizaje autom√°tico  (Machine Learning) capaz de clasificar im√°genes de forma binaria, identificando si pertenecen a un **gato** o un **conejo**. A trav√©s del entrenamiento con un conjunto de im√°genes variadas, el modelo busca aprender a reconocer patrones visuales distintivos entre ambas especies, incluso en presencia de diferentes posturas, razas y fondos.

## Descripci√≥n del Dataset

El conjunto de datos utilizado fue obtenido de la plataforma Kaggle. Contiene im√°genes de **gatos y conejos** en diversas condiciones: m√∫ltiples razas, posturas y escenarios visuales, lo que permite entrenar un modelo m√°s robusto y generalizable.

### Caracter√≠sticas del dataset:

- Contiene **2,000 im√°genes** distribuidas en las capetas test, train y validation:
    - `Cat`: 1,000 im√°genes de gatos
        - Train: 800 im√°genes
        - Test: 10 im√°genes
        - Validation: 207 im√°genes
    - `Rabbit`: 1,000 im√°genes
        - Train: 800 im√°genes
        - Test: 5 im√°genes
        - Validation: 207 im√°genes
- Formato de imagen: `.jpg`
- No contiene etiquetas adicionales como raza, edad o ubicaci√≥n.
- Todas las im√°genes ya han sido redimensionadas a (300, 300).

### Obtener, generar o aumentar un set de datos.
El dataset utilizado fue descargado desde la plataforma Kaggle [(Munir Yadi, ‚ÄúCat vs Rabbit‚Äù)](https://www.kaggle.com/datasets/muniryadi/cat-vs-rabbit) 

Se redistribuy√≥ de forma manual la informaci√≥n contenida en el dataset y realiz√≥ una limpieza en los datos que presentaban elementos no relacionados (im√°genes con demasiado zoom unicamente de pelaje, im√°genes de pasto) para tener un mejor equilibro en los datos para entrenar, validar y probar el modelo de ML

- Entrenamiento: 70%
    - `Cat:` 700 im√°genes
    - `Rabbit`: 700 im√°genes
- Validaci√≥n: 15%
    - `Cat:` 150 im√°genes
    - `Rabbit`: 150 im√°genes
- Prueba: 15%
    - `Cat:` 150 im√°genes
    - `Rabbit`: 150 im√°genes
    

### Escalamiento y Preprocesado de Datos
Para mejorar el rendimiento y la capacidad de generalizaci√≥n del modelo, se implementaron t√©cnicas de preprocesado utilizando TensorFlow y Keras. 

Las im√°genes originales ten√≠an un tama√±o de 300x300 p√≠xeles, pero se redimensionaron a 150x150 para poder acelerar el entrenamiento y reducir el uso de memoria (RAM o GPU) adem√°s, simplica los c√°lculos al disminuir la cantidad de p√≠xeles por imagen.

Igualmente preserva suficiente informaci√≥n visual para tareas de clasificaci√≥n binaria como en este caso es la distinci√≥n entre gatos y conejos, ya que estas clases tienen caracter√≠sticas f√°cilmente detectables incluso a menor resoluci√≥n no hace falta tener una alta resoluci√≥n para poder distinguir entre ambas especies.

- `rescale = 1./255,` : Convierte los valores de p√≠xeles de [0, 255] a [0, 1]
- `rotation_range=20`:  Gira aleatoriamente la imagen en un rango de ¬±20 grados
- `width_shift_range=0.1`:  Desplaza la imagen horizontalmente hasta un 10%
- `height_shift_range=0.2`: Desplaza la imagen verticalmente hasta un 10%
- `zoom_range=0.15`: Aplica un zoom aleatorio de hasta un 15%
- `horizontal_flip = True:` Invierte horizontalmente la imagen de forma aleatoria
- `brightness_range=[0.5, 1.2]:` Ajusta aleatoriamente el brillo entre 50% y 120%

## Implementaci√≥n del modelo
### Algoritmo 

La tarea de clasificar im√°genes de gatos y conejos implica afrontar variaciones de iluminaci√≥n, fondo, pelajes y poses. Para abordar estos desaf√≠os se evaluaron distintos enfoques (SVM, HOG¬†+¬†SVM, Random Forest), pero finalmente se opt√≥ por una Convolutional Neural Network (CNN) debido a los siguientes factores clave:

- **Aprendizaje autom√°tico de caracter√≠sticas:** 
    A diferencia de HOG o SIFT, la CNN aprende jerarqu√≠as de bordes, texturas y formas directamente de los p√≠xeles sin ingenier√≠a manual.

- **Buen desempe√±o con conjuntos de datos moderados:**  
   Con solo 2 000 im√°genes, t√©cnicas de *data augmentation* (rotaciones, flips, cambios de brillo) permiten a la CNN generalizar mejor que modelos tradicionales con caracter√≠sticas fijas.

- **Flexibilidad para adaptarse a diferentes tama√±os de im√°genes:** 
    Las convoluciones y el pooling permiten entrenar la red con resoluciones variables sin perder detalles importantes. Esto facilita integrar fotos obtenidas con c√°maras distintas (smartphone, DSLR, webcam) sin reescalar todo a un tama√±o fijo, manteniendo la nitidez cuando est√° disponible. (Sin embargo esta se modific√≥ por temas de rendimiento)

La elecci√≥n de una Convolutional Neural Network (CNN) para la clasificaci√≥n binaria de gatos y conejos se fundamenta en que, aunque ambas especies comparten rasgos generales (pelaje y siluetas similares), existen detalles visuales finos como longitud y posici√≥n de las orejas, forma del hocico, proporciones de la cabeza; que la arquitectura convolucional aprende de forma jer√°rquica y autom√°tica. 

El conjunto de ‚âà 2 000 im√°genes disponible, reforzado con t√©cnicas de data augmentation (volteos, rotaciones leves, ajustes de brillo), proporciona la diversidad necesaria para entrenar la red reduciendo las posibilidades de tener un overtfitting.

Adem√°s, muchos de los conceptos y herramientas empleados (capas convolucionales, pooling, data augmentation, capas flatten y densas) ya se trabajaron en clase, lo que facilita la implementaci√≥n pr√°ctica. As√≠, la CNN ofrece la combinaci√≥n √≥ptima de precisi√≥n, robustez ante variaciones de fondo e iluminaci√≥n y escalabilidad para incorporar nuevas clases en el futuro con un ajuste m√≠nimo.


### Para la implementaci√≥n del modelo se utilizaron los siguientes papers:

- [Custom CNN architectures for skin disease classification: binary and multi-class performance](https://www.semanticscholar.org/paper/Custom-CNN-architectures-for-skin-disease-binary-Gupta-Nirmal/26208d4b3255702dfe9ec6b257c7a6d6d8c2dd95?)

- [Binary Image Classification Through an Optimal Topology for Convolutional Neural Networks](https://asrjetsjournal.org/index.php/American_Scientific_Journal/article/view/5938)


## Arquitectura de una CNN y Model
### **¬øQu√© es una CNN?**
Una red neuronal convolucional (CNN) es un tipo de red neuronal artificial, especialmente efectiva para el procesamiento y an√°lisis de datos visuales como im√°genes y videos. Se basa en el principio de las convoluciones para extraer caracter√≠sticas de la entrada y luego las usa para realizar tareas como clasificaci√≥n, detecci√≥n de objetos, segmentaci√≥n, entre otras. 

Las CNN est√°n compuestas por tres tipos de capas: 

- Capa de convoluci√≥n.
- Capa de agrupaci√≥n.
- Capa completamente conectada (relu y salida). 

<img src="assets/Arquitectura_CNN.png" width="600">


- `Capa convolucional (Conv2D)` :
    - Se define una capa convolucional con 32 filtros de tama√±o 3 √ó 3 y funci√≥n de activaci√≥n ReLU.
    - La capa espera entradas de im√°genes con tama√±o 150 √ó 150 p√≠xeles y 3 canales de color (RGB).
    - Al aplicar cada filtro, se produce un mapa de activaci√≥n que resalta bordes y texturas b√°sicas presentes en las fotos de gatos y conejos.
    - ReLU deja pasar valores positivos y pone en cero los negativos para que la red aprenda mejor.

- `Capa de agrupaci√≥n (MaxPooling2D)` :
    -  Se aplica un MaxPooling con ventana 2 √ó 2 para reducir la salida de la capa convolucional anterior.
    -  La capa de pooling reduce la dimensionalidad de la imagen al agrupar regiones adyacentes de p√≠xeles y tomar el valor m√°ximo de cada regi√≥n
    -  Esto ayuda a reducir la cantidad de par√°metros y se mantiene la informaci√≥n m√°s relevante para la clasificaci√≥n.


- `Segunda capa convolucional (Conv2D)` :
    - Contiene 64 filtros de tama√±o 3 √ó 3 y activaci√≥n ReLU.
    - Detecta patrones m√°s complejos.
    - ReLU vuelve a filtrar los valores negativos, acelerando el aprendizaje.

- `Segunda capa de agrupaci√≥n (MaxPooling2D)` :
    - MaxPooling 2 √ó 2 reduce nuevamente las dimensiones espaciales.
    - Se mantiene la informaci√≥n m√°s relevante para la clasificaci√≥n.


- `Tercera capa convolucional (Conv2D)` :
    - Contiene 128 filtros de tama√±o 3 √ó 3 y activaci√≥n ReLU.
    - Identifica patrones a√∫n m√°s complejos.

- `Tercera capa de agrupaci√≥n (MaxPooling2D)` :
    -  MaxPooling 2 √ó 2 reduce nuevamente las dimensiones espaciales.
    - Se mantiene la informaci√≥n m√°s relevante para la clasificaci√≥n.


- `Aplanar salida (Flatten)` :
    - Convierte la salida de las capas convolucionales y de pooling en un vector unidimensional.
    - Prepara los datos para conectarse con las neuronas densas.

- `Capa densa (Dense)` :
    - Se define primero una capa densa con 512 neuronas y funci√≥n de activaci√≥n ReLU.

- `Capa de salida (Dense)` :
    - Tiene 1 neurona con activaci√≥n sigmoide.
    - Devuelve un valor entre 0 y 1 que indica la probabilidad de que la imagen sea de una clase (configuraci√≥n t√≠pica para problemas de clasificaci√≥n binaria).


## Resultados y Evaluaci√≥n del Modelo
