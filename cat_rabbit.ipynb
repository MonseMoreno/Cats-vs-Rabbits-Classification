{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a1b47b",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62925e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c72097",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94cea521",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"data\"\n",
    "train_dir = os.path.join(base_dir, 'train-cat-rabbit')\n",
    "test_dir = os.path.join(base_dir, 'test-images')\n",
    "valid_dir = os.path.join(base_dir, 'val-cat-rabbit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ba6989",
   "metadata": {},
   "source": [
    "#### Técnicas de Escalamiento y Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd14370",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "#Técnicas de preprocesamiento de datos para mejorar la categorización del modelo\n",
    "\t\t\t\trescale = 1./255, \n",
    "\t\t\t\trotation_range = 20, \n",
    "\t\t\t\twidth_shift_range = 0.1, \n",
    "    \t\t\theight_shift_range=0.1,\n",
    "\t\t\t\tzoom_range = 0.15,\n",
    "\t\t\t\thorizontal_flip = True,\n",
    "\t\t\t\tbrightness_range=[0.5, 1.2] \n",
    "    )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(1./255)  # Escala los píxeles de las imágenes de validación al rango [0, 1]\n",
    "test_datagen = ImageDataGenerator(1./255)        # Escala los píxeles de las imágenes de prueba al rango [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medida de las imágenes\n",
    "images_size = (150, 150)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\t\t\t\t\t\t\ttrain_dir,\n",
    "\t\t\t\t\t\t\ttarget_size = images_size, # Tamaño al que se redimensionan las imágenes\n",
    "\t\t\t\t\t\t\tbatch_size = 10,  # Tamaño del lote de imágenes por batch\n",
    "\t\t\t\t\t\t\tclass_mode ='binary', # Tipo de etiquetas: 'binary' porque hay dos clases (gato y conejo)\n",
    "       \t\t\t\t\t\tshuffle = True \n",
    "\t\t\t\t\t\t\t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "f, axarr = plt.subplots(1, 5, figsize=(30, 8))\n",
    "\n",
    "for i in range(5) :\n",
    "  \taxarr[i].imshow(train_generator[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar imágenes y las etiquetas despúes de escalamiento y preprocesado\n",
    "images, labels = train_generator[0]\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "print(images.shape)\n",
    "print(labels)\n",
    "\n",
    "plt.figure()\n",
    "f, axarr = plt.subplots(1, images.shape[0], figsize=(30, 7))\n",
    "\n",
    "for i in range(images.shape[0]):\n",
    "    axarr[i].imshow(images[i])\n",
    "    axarr[i].set_title(class_names[int(labels[i])], fontsize=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc601b3",
   "metadata": {},
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e4647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo CNN\n",
    "\n",
    "model = Sequential([\n",
    "    \n",
    "    # Capa 1: Convolucional con 32 filtros de 3x3, función de activación ReLU, y tamaño de entrada 150x150x3 \n",
    "    # Capa de MaxPooling para redicir las dimensiones de la salida\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Capa 2: Convolucional con 64 filtros de 3x3, función de activación ReLU \n",
    "    # Capa de MaxPooling para redicir las dimensiones de la salida    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #Capa 3: Convolucional con 128 filtros de 3x3, función de activación ReLU\n",
    "    #Capa de MaxPooling para redicir las dimensiones de la salida\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #Aplanar la salida para pasarla a capas más densas\n",
    "    #Capa densa con 512 neuronas y función de activación ReLU\n",
    "    #Capa de salida con una neurona de activación sigmoide para clasificar los gatos y conejos\n",
    "    Flatten(),\n",
    "    Dense(512, activation= \"relu\"),\n",
    "    Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "\n",
    "# Compilar el modelo con optimizador Adam, pérdida binaria y métrica de precisión\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Mostrar resumen de la arquitectura del modelo\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
